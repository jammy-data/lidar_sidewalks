{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d512d5",
   "metadata": {},
   "source": [
    "# Classification of roads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc42c90",
   "metadata": {},
   "source": [
    "We're going to look into the success of classifying algorithms on the LiDAR data we have with a couple of different techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2aaff",
   "metadata": {},
   "source": [
    "### The following are the list of classifications defined by IFP\n",
    "- 0 not yet classified (nothing done yet)\n",
    "- 1 unclassified (actively marked as nothing)\n",
    "- 2 ground, sidewalk\n",
    "- 3,4,5 vegetation, low(gras) medium(shrubbery) high (trees)\n",
    "- 6 buildings\n",
    "- 8 street furniture\n",
    "- 10 street markings\n",
    "- 11 street, pavement\n",
    "- 12 bike lanes\n",
    "- 13 temporary things(bicycles, trashcans)\n",
    "- 15 cars, trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import seaborn as sns\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from upath import UPath\n",
    "import os\n",
    "# Load environment variables from .env file if it exists\n",
    "load_dotenv()\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from src import data_loader\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.fetch_and_process_lidar(\"riga.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def las_in_memory_size(las):\n",
    "    \"\"\"\n",
    "    Estimate the in-memory size (in bytes) of a laspy LAS object.\n",
    "    \"\"\"\n",
    "    total_size = 0\n",
    "    for dim in list(las.point_format.dimension_names):\n",
    "        arr = getattr(las, dim)\n",
    "        total_size += arr.nbytes if hasattr(arr, 'nbytes') else sys.getsizeof(arr)\n",
    "    return total_size\n",
    "\n",
    "# Example usage:\n",
    "# las = laspy.read(\"your_file.las\")\n",
    "# print(f\"In-memory size: {las_in_memory_size(las)/1e6:.2f} MB\")\n",
    "\n",
    "def describe_las(las):\n",
    "    print(f\"In-memory size: {las_in_memory_size(las)/1e6:.2f} MB\")\n",
    "    print(f\"Point Format: {las.header.point_format}\")\n",
    "    print(f\"Number of Points: {las.header.point_count}\")\n",
    "    print(\"Available Dimensions:\", list(las.point_format.dimension_names))\n",
    "    print(\"Bounding Box:\")\n",
    "    print(f\"  X: {las.header.mins[0]} to {las.header.maxs[0]}\")\n",
    "    print(f\"  Y: {las.header.mins[1]} to {las.header.maxs[1]}\")\n",
    "    print(f\"  Z: {las.header.mins[2]} to {las.header.maxs[2]}\")\n",
    "    print(\"Scale:\", las.header.scales)\n",
    "    print(\"Offset:\", las.header.offsets)\n",
    "    try:\n",
    "        print(\"CRS:\", las.header.parse_crs())\n",
    "    except:\n",
    "        print(\"CRS: Not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "las = laspy.read(\"../data/bologna_filtered.las\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3150ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_las(las)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5bc2f",
   "metadata": {},
   "source": [
    "### The las is pretty huge, so we need to sample it up (ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laspy import read\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fields of interest\n",
    "fields = ['X', 'Y', 'Z', 'intensity', 'red', 'green', 'blue', 'classification']\n",
    "\n",
    "df = pd.DataFrame({field: np.asarray(getattr(las, field)) for field in fields})\n",
    "\n",
    "# Optimize data types to reduce memory consumption by ~30%\n",
    "df['intensity'] = df['intensity'].astype(np.uint16)\n",
    "df['red'] = df['red'].astype(np.uint16)\n",
    "df['green'] = df['green'].astype(np.uint16)\n",
    "df['blue'] = df['blue'].astype(np.uint16)\n",
    "df['classification'] = df['classification'].astype(np.uint8)  # Only need 0-15 values\n",
    "\n",
    "print(f\"‚úÖ Data loaded with optimized dtypes\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f249a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(df, n=2_000_000, seed=None):\n",
    "    return df.sample(n=n, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# NOTE: Don't store all samples in memory at once\n",
    "# Instead, create them on-demand during training to save ~8GB of RAM\n",
    "print(\"‚úÖ Sample function ready. Samples will be created on-demand.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67753c",
   "metadata": {},
   "source": [
    "## Supervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c58923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0. Imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "random_state = 42\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import layers, models\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcdfd3",
   "metadata": {},
   "source": [
    "## Experiment A: Using all of the pointcloud classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(X_train, X_test, y_train, y_test, class_weight=\"balanced\", n_estimators=200):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                 class_weight=class_weight,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, digits=3, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "    return clf, clf.classes_, report, cm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion(cm, classes, title=\"Confusion matrix\", normalize=False, cmap=\"Blues\"):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix, with optional normalization to percentages.\n",
    "\n",
    "    Args:\n",
    "        cm (array): confusion matrix (from sklearn.metrics.confusion_matrix)\n",
    "        classes (list): list of class names\n",
    "        title (str): plot title\n",
    "        normalize (bool): if True, show percentages instead of counts\n",
    "        cmap (str): color map\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = \".2f\"\n",
    "        title = title + \" (normalized %)\"\n",
    "    else:\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=cmap, \n",
    "                xticklabels=classes, yticklabels=classes,\n",
    "                cbar=True, square=True)\n",
    "\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6945202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# --- Config ---\n",
    "features = ['Z', 'intensity', 'red', 'green', 'blue'] # take away X and Y as they are likely to differ spatially if applied to different cities.\n",
    "label_col = 'classification'\n",
    "n_samples = 1_000_000   # REDUCED: was 2M (saves ~1.5GB per model)\n",
    "n_models = 3            # how many separate models to train\n",
    "random_seeds = [42, 101, 202]  # reproducible seeds\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Multi-sample training loop ---\n",
    "for i, seed in enumerate(random_seeds[:n_models], start=1):\n",
    "    print(f\"\\nüß© Training model {i}/{n_models} on a random {n_samples:,} points...\")\n",
    "\n",
    "    # Sample randomly from the full dataset\n",
    "    sample_df = df.sample(n=n_samples, random_state=seed)\n",
    "\n",
    "    # Split\n",
    "    X = sample_df[features].values\n",
    "    y = sample_df[label_col].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Train (reuses your function) - REDUCED: 100 estimators instead of 200\n",
    "    clf, classes, report, cm = train_and_eval(X_train, X_test, y_train, y_test, n_estimators=100)\n",
    "\n",
    "    # Collect results\n",
    "    results.append({\n",
    "        \"seed\": seed,\n",
    "        \"model\": clf,\n",
    "        \"classes\": classes,\n",
    "        \"report\": report,\n",
    "        \"confusion\": cm\n",
    "    })\n",
    "\n",
    "    # CLEANUP: Delete intermediate arrays and force garbage collection\n",
    "    del sample_df, X, y, X_train, X_test, y_train, y_test\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"‚úÖ Finished model {i}/{n_models}\")\n",
    "    print(pd.DataFrame(report).T)\n",
    "    plot_confusion(cm, classes, title=f\"Confusion matrix (sample {i})\", normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e12dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also see all of the models' performance together by averaging their reports\n",
    "all_reports = pd.concat([\n",
    "    pd.DataFrame(r[\"report\"]).T.assign(seed=r[\"seed\"]) for r in results\n",
    "])\n",
    "display(all_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be56a4",
   "metadata": {},
   "source": [
    "> Sidenote: The thing I've found based on the exploration here is that when X and Y are removed from the equation, there is a DRASTIC reduction in accuracy. The model was hugely leveraging space as a predictive variable. Whilst we can keep this in, it makes it non-transferrable to other locations (unless we normalise and remove the exact geospatial co-ordinate, making each point relative to the points next to it).\n",
    "\n",
    "> Better yet, we can use the calculated features, such as normals and slope, that Hendrik calculated in the larger pointcloud. Pro is this could improve accuracy for a single model for use in all pointclouds. Trade off is this file is absolutely huge. Still... We can implement all features and trim them off as and when..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fdf9b",
   "metadata": {},
   "source": [
    "## Experiment B: Using a 3 class system (Sidewalk, road, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sidewalk_set = {2}\n",
    "carriageway_set = {11}\n",
    "\n",
    "def collapse_label(orig):\n",
    "    if orig in sidewalk_set:\n",
    "        return \"sidewalk\"\n",
    "    elif orig in carriageway_set:\n",
    "        return \"carriageway\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_3class\"] = df[\"classification\"].apply(collapse_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535234bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_3class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# --- Config ---\n",
    "features = ['X', 'Y', 'Z', 'intensity', 'red', 'green', 'blue']\n",
    "label_col = 'label_3class'\n",
    "n_samples = 1_000_000   # REDUCED: was 2M (saves ~1.5GB per model)\n",
    "n_models = 3            # how many separate models to train\n",
    "random_seeds = [42, 101, 202]  # reproducible seeds\n",
    "\n",
    "results_3class = []  # Use different variable name to avoid memory issues\n",
    "\n",
    "# --- Multi-sample training loop ---\n",
    "for i, seed in enumerate(random_seeds[:n_models], start=1):\n",
    "    print(f\"\\nüß© Training model {i}/{n_models} on a random {n_samples:,} points...\")\n",
    "\n",
    "    # Sample randomly from the full dataset\n",
    "    sample_df = df.sample(n=n_samples, random_state=seed)\n",
    "\n",
    "    # Split\n",
    "    X = sample_df[features].values\n",
    "    y = sample_df[label_col].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, stratify=y, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Train (reuses your function) - REDUCED: 100 estimators instead of 200\n",
    "    clf, classes, report, cm = train_and_eval(X_train, X_test, y_train, y_test, n_estimators=100)\n",
    "\n",
    "    # Collect results\n",
    "    results_3class.append({\n",
    "        \"seed\": seed,\n",
    "        \"model\": clf,\n",
    "        \"classes\": classes,\n",
    "        \"report\": report,\n",
    "        \"confusion\": cm\n",
    "    })\n",
    "\n",
    "    # CLEANUP: Delete intermediate arrays and force garbage collection\n",
    "    del sample_df, X, y, X_train, X_test, y_train, y_test\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"‚úÖ Finished model {i}/{n_models}\")\n",
    "    print(pd.DataFrame(report).T)\n",
    "    plot_confusion(cm, classes, title=f\"Confusion matrix (sample {i})\", normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2d682",
   "metadata": {},
   "source": [
    "## Experiment C: Spatial Validation with Tile-based Split\n",
    "\n",
    "This experiment tests **transfer learning** by holding out complete spatial tiles from the training set. This simulates deploying the model to a new area of the same city, which is more realistic than random train/test splitting.\n",
    "\n",
    "**Key question:** Does the model trained on one region work on an unseen spatial region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5695c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Create spatial tiles (grid-based) ---\n",
    "# Divide the bounding box into tiles\n",
    "n_tiles_x = 4  # Create a 4x4 grid\n",
    "n_tiles_y = 4\n",
    "\n",
    "x_min, x_max = df['X'].min(), df['X'].max()\n",
    "y_min, y_max = df['Y'].min(), df['Y'].max()\n",
    "\n",
    "print(f\"Bounding box: X=[{x_min:.1f}, {x_max:.1f}], Y=[{y_min:.1f}, {y_max:.1f}]\")\n",
    "\n",
    "# Create tile assignment using numpy arrays (avoids memory issues)\n",
    "x_linspace = np.linspace(x_min, x_max, n_tiles_x + 1)\n",
    "y_linspace = np.linspace(y_min, y_max, n_tiles_y + 1)\n",
    "\n",
    "tile_x = np.digitize(df['X'].values, x_linspace) - 1\n",
    "tile_y = np.digitize(df['Y'].values, y_linspace) - 1\n",
    "\n",
    "# Clip to valid range to handle edge cases\n",
    "tile_x = np.clip(tile_x, 0, n_tiles_x - 1)\n",
    "tile_y = np.clip(tile_y, 0, n_tiles_y - 1)\n",
    "\n",
    "# Create tile IDs as numpy array (efficient)\n",
    "tile_ids = np.array([f\"{tx}_{ty}\" for tx, ty in zip(tile_x, tile_y)])\n",
    "\n",
    "# Count distribution\n",
    "unique_tiles, counts = np.unique(tile_ids, return_counts=True)\n",
    "print(f\"\\n‚úÖ Created {len(unique_tiles)} spatial tiles ({n_tiles_x}x{n_tiles_y} grid)\")\n",
    "print(f\"Tile distribution:\")\n",
    "for tile, count in sorted(zip(unique_tiles, counts)):\n",
    "    print(f\"  {tile}: {count:,} points\")\n",
    "\n",
    "# CLEANUP: Delete large tile assignment arrays\n",
    "del tile_x, tile_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/test split by spatial tiles ---\n",
    "# Hold out one tile for testing, train on the rest\n",
    "features = ['X', 'Y', 'Z', 'intensity', 'red', 'green', 'blue']\n",
    "label_col = 'classification'\n",
    "\n",
    "# Select a tile to hold out (e.g., tile 2_2 - center)\n",
    "test_tile = '2_2'\n",
    "train_mask = tile_ids != test_tile\n",
    "test_mask = tile_ids == test_tile\n",
    "\n",
    "# MEMORY OPTIMIZATION: Use numpy indexing to convert directly to arrays\n",
    "# This avoids creating dataframe copies\n",
    "train_indices = np.where(train_mask)[0]\n",
    "test_indices = np.where(test_mask)[0]\n",
    "\n",
    "X_train_spatial = df.iloc[train_indices][features].values\n",
    "y_train_spatial = df.iloc[train_indices][label_col].values\n",
    "\n",
    "X_test_spatial = df.iloc[test_indices][features].values\n",
    "y_test_spatial = df.iloc[test_indices][label_col].values\n",
    "\n",
    "print(f\"üìç Spatial Split Configuration:\")\n",
    "print(f\"   Training tiles: all except {test_tile}\")\n",
    "print(f\"   Training points: {len(train_indices):,}\")\n",
    "print(f\"   Test tile: {test_tile}\")\n",
    "print(f\"   Test points: {len(test_indices):,}\")\n",
    "print(f\"   Test data ratio: {len(test_indices) / len(df) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Spatial split complete (using numpy arrays to save memory)\")\n",
    "print(f\"   Training array shape: {X_train_spatial.shape}\")\n",
    "print(f\"   Test array shape: {X_test_spatial.shape}\")\n",
    "\n",
    "# CLEANUP: Delete index arrays and masks\n",
    "del train_indices, test_indices, train_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# --- Clean up large dataframes to free memory ---\n",
    "print(\"üßπ Cleaning up large dataframes...\", flush=True)\n",
    "print(f\"   Deleted: df, tile_ids\", flush=True)\n",
    "\n",
    "del df, tile_ids\n",
    "gc.collect()\n",
    "\n",
    "print(f\"‚úÖ Memory freed - numpy arrays retained for training\", flush=True)\n",
    "print(f\"   Training array shape: {X_train_spatial.shape}\", flush=True)\n",
    "print(f\"   Test array shape: {X_test_spatial.shape}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f85ed",
   "metadata": {},
   "source": [
    "### this cell takes a LONG time without HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model on spatial split ---\n",
    "import time\n",
    "\n",
    "print(\"üß© Training model on spatial split (all surrounding tiles)...\\n\")\n",
    "print(f\"   Training set size: {len(X_train_spatial):,} points\")\n",
    "print(f\"   Test set size: {len(X_test_spatial):,} points\")\n",
    "print(f\"   Features: {len(features)}\")\n",
    "print(f\"   Estimators: 200\")\n",
    "print(\"\\n‚è≥ This may take 5-15 minutes depending on system...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_spatial, classes_spatial, report_spatial, cm_spatial = train_and_eval(\n",
    "    X_train_spatial, X_test_spatial, y_train_spatial, y_test_spatial,\n",
    "    class_weight=\"balanced\", n_estimators=200\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(\"\\nüìä Performance on held-out spatial tile:\")\n",
    "print(pd.DataFrame(report_spatial).T)\n",
    "plot_confusion(cm_spatial, classes_spatial, \n",
    "               title=f\"Spatial Validation: Test on tile {test_tile}\", normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1b497",
   "metadata": {},
   "source": [
    "### Run this cell instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ec2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FASTER VERSION: Train on sampled data ---\n",
    "# This is much faster while still being statistically valid\n",
    "import time\n",
    "import sys\n",
    "\n",
    "print(\"üß© FASTER: Training model on SAMPLED spatial split...\\n\", flush=True)\n",
    "\n",
    "# Sample training data for faster training (still statistically sound)\n",
    "print(\"   Sampling training data...\", flush=True)\n",
    "sample_size = 1_000_000  # Use 1M points instead of all\n",
    "sample_fraction = min(1.0, sample_size / len(X_train_spatial))\n",
    "train_mask = np.random.RandomState(42).rand(len(X_train_spatial)) < sample_fraction\n",
    "X_train_sample = X_train_spatial[train_mask]\n",
    "y_train_sample = y_train_spatial[train_mask]\n",
    "\n",
    "print(f\"   Sampled training set: {len(X_train_sample):,} points (from {len(X_train_spatial):,})\", flush=True)\n",
    "print(f\"   Full test set: {len(X_test_spatial):,} points\", flush=True)\n",
    "print(f\"   Features: {len(features)}\", flush=True)\n",
    "print(f\"   Estimators: 100 (reduced for speed)\", flush=True)\n",
    "print(\"\\n‚è≥ This should take 2-5 minutes...\\n\", flush=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_spatial_fast, classes_spatial_fast, report_spatial_fast, cm_spatial_fast = train_and_eval(\n",
    "    X_train_sample, X_test_spatial, y_train_sample, y_test_spatial,\n",
    "    class_weight=\"balanced\", n_estimators=100\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\", flush=True)\n",
    "print(\"\\nüìä Performance on held-out spatial tile:\", flush=True)\n",
    "print(pd.DataFrame(report_spatial_fast).T)\n",
    "plot_confusion(cm_spatial_fast, classes_spatial_fast, \n",
    "               title=f\"Spatial Validation (FAST): Test on tile {test_tile}\", normalize=True)\n",
    "\n",
    "# Store for comparison\n",
    "report_spatial = report_spatial_fast\n",
    "cm_spatial = cm_spatial_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ca36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd475d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d15b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare: Random vs Spatial Split ---\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARISON: Random Split vs Spatial Split\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract accuracy metrics from both experiments\n",
    "random_split_results = results[0]  # From Experiment A (all classes)\n",
    "spatial_split_report = report_spatial\n",
    "\n",
    "# Compare accuracy for each class\n",
    "print(\"\\nüéØ Overall Accuracy:\")\n",
    "print(f\"   Random split (Exp A):  {random_split_results['report']['accuracy']:.4f}\")\n",
    "print(f\"   Spatial split (Exp C): {spatial_split_report['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Per-class F1-scores:\")\n",
    "# Iterate over keys in the report that are class labels (stored as strings)\n",
    "for key in random_split_results['report'].keys():\n",
    "    # Skip non-numeric keys like 'accuracy', 'macro avg', 'weighted avg', etc.\n",
    "    try:\n",
    "        class_label = int(key)  # Try to convert string key to int\n",
    "        # Now check both the string key and int key in the spatial report\n",
    "        if key in spatial_split_report:\n",
    "            random_f1 = random_split_results['report'][key]['f1-score']\n",
    "            spatial_f1 = spatial_split_report[key]['f1-score']\n",
    "            diff = spatial_f1 - random_f1\n",
    "            symbol = \"üìâ\" if diff < -0.05 else \"üìà\" if diff > 0.05 else \"‚û°Ô∏è\"\n",
    "            print(f\"   Class {class_label:2} | Random: {random_f1:.3f} | Spatial: {spatial_f1:.3f} | Œî {diff:+.3f} {symbol}\")\n",
    "    except (ValueError, KeyError):\n",
    "        # Skip keys that can't be converted to int or aren't in spatial report\n",
    "        pass\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"   ‚Ä¢ If spatial performance is similar ‚Üí model generalizes well to unseen regions\")\n",
    "print(\"   ‚Ä¢ If spatial performance drops significantly ‚Üí model is overfitting to local patterns\")\n",
    "print(\"   ‚Ä¢ Spatial validation is more realistic for deployment to new areas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf73c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "881ec7ef",
   "metadata": {},
   "source": [
    "### This cell checks for tile contiguity and computes mean tile parameters for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47babc6f",
   "metadata": {},
   "source": [
    "**Motivation:** We've found that random selection of tiles for training the model actually moderately increases accuracy. Now this could be because we¬¥re currently just taking a sample of 1m and may change if we're using all of them. This is why we're going to take the radioetric properties of each contiguous cell, because if we have a random sample across the pointcloud, we might be creating a more general model, rather than a localised one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79192b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diagnostics: tiles, radiometrics, SHAP analysis, and plotting helpers ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# Assumptions:\n",
    "# - `X_train_spatial`, `X_test_spatial` are numpy arrays with columns [X, Y, Z, intensity, red, green, blue]\n",
    "# - `report_spatial` and `results` exist from earlier cells\n",
    "# - `clf` (random model) and `clf_spatial_fast` exist if you ran both training cells\n",
    "\n",
    "feature_names = ['X', 'Y', 'Z', 'intensity', 'red', 'green', 'blue']\n",
    "\n",
    "# 1) Reconstruct tile grid from combined spatial arrays (safe if `df` was deleted)\n",
    "all_XY = np.vstack([X_train_spatial[:, :2], X_test_spatial[:, :2]])\n",
    "\n",
    "n_tiles_x = globals().get('n_tiles_x', 4)\n",
    "n_tiles_y = globals().get('n_tiles_y', 4)\n",
    "\n",
    "x_min, x_max = all_XY[:,0].min(), all_XY[:,0].max()\n",
    "y_min, y_max = all_XY[:,1].min(), all_XY[:,1].max()\n",
    "\n",
    "x_linspace = np.linspace(x_min, x_max, n_tiles_x + 1)\n",
    "y_linspace = np.linspace(y_min, y_max, n_tiles_y + 1)\n",
    "\n",
    "# helper to compute tile ids for an XY array\n",
    "def compute_tile_ids(xy):\n",
    "    tx = np.digitize(xy[:,0], x_linspace) - 1\n",
    "    ty = np.digitize(xy[:,1], y_linspace) - 1\n",
    "    tx = np.clip(tx, 0, n_tiles_x - 1)\n",
    "    ty = np.clip(ty, 0, n_tiles_y - 1)\n",
    "    return np.array([f\"{a}_{b}\" for a,b in zip(tx, ty)])\n",
    "\n",
    "# Compute tile_ids for train and test arrays\n",
    "tile_ids_train = compute_tile_ids(X_train_spatial[:, :2])\n",
    "tile_ids_test = compute_tile_ids(X_test_spatial[:, :2])\n",
    "\n",
    "# Quick contiguity check: plot a small sample colored by tile id\n",
    "def plot_tile_samples(sample_size=200000):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # sample from combined XY\n",
    "    total = len(tile_ids_train) + len(tile_ids_test)\n",
    "    sample_size = min(sample_size, total)\n",
    "    # sample proportionally from train and test\n",
    "    n_train = int(sample_size * (len(tile_ids_train)/total))\n",
    "    n_test = sample_size - n_train\n",
    "\n",
    "    idx_train = np.random.RandomState(0).choice(len(tile_ids_train), n_train, replace=False) if n_train>0 else np.array([], dtype=int)\n",
    "    idx_test = np.random.RandomState(1).choice(len(tile_ids_test), n_test, replace=False) if n_test>0 else np.array([], dtype=int)\n",
    "\n",
    "    XY_sample = np.vstack([X_train_spatial[idx_train, :2] if n_train>0 else np.zeros((0,2)),\n",
    "                           X_test_spatial[idx_test, :2] if n_test>0 else np.zeros((0,2))])\n",
    "    tile_sample = np.concatenate([tile_ids_train[idx_train] if n_train>0 else np.array([], dtype=object),\n",
    "                                  tile_ids_test[idx_test] if n_test>0 else np.array([], dtype=object)])\n",
    "\n",
    "    # map tile ids to integer colors\n",
    "    unique_tiles = np.unique(tile_sample)\n",
    "    tile_to_int = {t:i for i,t in enumerate(unique_tiles)}\n",
    "    colors = np.array([tile_to_int[t] for t in tile_sample])\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sc = plt.scatter(XY_sample[:,0], XY_sample[:,1], c=colors, s=1, cmap='tab20', alpha=0.8)\n",
    "    plt.title('Sampled points colored by spatial tile')\n",
    "    plt.xlabel('X'); plt.ylabel('Y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('üß≠ Running quick spatial contiguity plot (may sample up to 200k points)...')\n",
    "plot_tile_samples(sample_size=100000)\n",
    "\n",
    "# 2) Per-tile radiometrics: compute mean intensity and colors for each tile (train + test separately)\n",
    "\n",
    "def per_tile_radiometrics(X_arr, tile_ids_arr):\n",
    "    df_r = pd.DataFrame({\n",
    "        'tile': tile_ids_arr,\n",
    "        'intensity': X_arr[:,3].astype(float),\n",
    "        'red': X_arr[:,4].astype(float),\n",
    "        'green': X_arr[:,5].astype(float),\n",
    "        'blue': X_arr[:,6].astype(float)\n",
    "    })\n",
    "    grouped = df_r.groupby('tile').mean()\n",
    "    return grouped.sort_index()\n",
    "\n",
    "print('\\nüìä Computing per-tile radiometrics (train)...')\n",
    "train_radiom = per_tile_radiometrics(X_train_spatial, tile_ids_train)\n",
    "print(train_radiom)\n",
    "\n",
    "print('\\nüìä Computing per-tile radiometrics (test)...')\n",
    "test_radiom = per_tile_radiometrics(X_test_spatial, tile_ids_test)\n",
    "print(test_radiom)\n",
    "\n",
    "# Plot intensity differences across tiles\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.subplot(1,2,1)\n",
    "train_radiom['intensity'].plot(kind='bar'); plt.title('Train: mean intensity per tile')\n",
    "plt.subplot(1,2,2)\n",
    "test_radiom['intensity'].plot(kind='bar'); plt.title('Test: mean intensity per tile')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) SHAP analysis helpers (trees only). Uses small sample to limit RAM.\n",
    "print('\\nüß† Preparing SHAP analysis helpers (will sample up to 5000 rows).')\n",
    "\n",
    "def run_shap_for_model(model, X_array, feature_names, sample_size=5000):\n",
    "    try:\n",
    "        import shap\n",
    "    except Exception as e:\n",
    "        print('‚úñ shap not installed or failed to import. Install with `pip install shap` to run SHAP analysis.')\n",
    "        return None\n",
    "\n",
    "    n = min(sample_size, len(X_array))\n",
    "    idx = np.random.RandomState(0).choice(len(X_array), n, replace=False)\n",
    "    X_sample = X_array[idx]\n",
    "\n",
    "    # Use TreeExplainer for tree-based models\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    except Exception as e:\n",
    "        print('‚úñ TreeExplainer failed:', e)\n",
    "        return None\n",
    "\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "    # shap_values for multiclass is a list; convert to mean absolute across classes\n",
    "    if isinstance(shap_values, list):\n",
    "        # compute mean absolute shap across classes for each feature\n",
    "        abs_mean = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)\n",
    "        feature_imp = pd.Series(abs_mean, index=feature_names).sort_values(ascending=False)\n",
    "    else:\n",
    "        feature_imp = pd.Series(np.abs(shap_values).mean(axis=0), index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "    # Summary plot (may be slow) ‚Äî show if interactive\n",
    "    try:\n",
    "        shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return feature_imp\n",
    "\n",
    "# Run SHAP for random model (if available)\n",
    "if 'clf' in globals():\n",
    "    print('\\nüîé SHAP for random (global) model ‚Äî this may take a minute')\n",
    "    imp_random = run_shap_for_model(clf, np.vstack([X_train_spatial, X_test_spatial]), feature_names, sample_size=3000)\n",
    "    if imp_random is not None:\n",
    "        print('\\nFeature importance (random model):')\n",
    "        print(imp_random)\n",
    "\n",
    "if 'clf_spatial_fast' in globals():\n",
    "    print('\\nüîé SHAP for spatial model (fast) ‚Äî this may take a minute')\n",
    "    imp_spatial = run_shap_for_model(clf_spatial_fast, np.vstack([X_train_spatial, X_test_spatial]), feature_names, sample_size=3000)\n",
    "    if imp_spatial is not None:\n",
    "        print('\\nFeature importance (spatial model):')\n",
    "        print(imp_spatial)\n",
    "\n",
    "# 4) Tile plotting helpers: 2D scatter and optional Open3D 3D viewer\n",
    "\n",
    "def plot_tile_2d(tile_id, which='train', sample=50000):\n",
    "    if which == 'train':\n",
    "        Xarr, tids = X_train_spatial, tile_ids_train\n",
    "    else:\n",
    "        Xarr, tids = X_test_spatial, tile_ids_test\n",
    "    mask = (tids == tile_id)\n",
    "    if mask.sum() == 0:\n",
    "        print(f'No points for tile {tile_id} in {which}')\n",
    "        return\n",
    "    idx = np.where(mask)[0]\n",
    "    n = min(sample, len(idx))\n",
    "    sel = np.random.RandomState(0).choice(idx, n, replace=False)\n",
    "    XY = Xarr[sel, :2]\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(XY[:,0], XY[:,1], s=1)\n",
    "    plt.title(f'Tile {tile_id} ({which}) ‚Äî {n} points')\n",
    "    plt.xlabel('X'); plt.ylabel('Y')\n",
    "    plt.show()\n",
    "\n",
    "def plot_tile_3d_open3d(tile_id, which='train', sample=100000):\n",
    "    try:\n",
    "        import open3d as o3d\n",
    "    except Exception as e:\n",
    "        print('Open3D not available.')\n",
    "        return\n",
    "    if which == 'train':\n",
    "        Xarr, tids = X_train_spatial, tile_ids_train\n",
    "    else:\n",
    "        Xarr, tids = X_test_spatial, tile_ids_test\n",
    "    mask = (tids == tile_id)\n",
    "    if mask.sum() == 0:\n",
    "        print(f'No points for tile {tile_id} in {which}')\n",
    "        return\n",
    "    idx = np.where(mask)[0]\n",
    "    n = min(sample, len(idx))\n",
    "    sel = np.random.RandomState(0).choice(idx, n, replace=False)\n",
    "    pts = Xarr[sel, :3]\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "    o3d.visualization.draw_geometries([pcd], window_name=f'Tile {tile_id} ({which})')\n",
    "\n",
    "print('\\n‚úÖ Diagnostics and helpers added. Examples:')\n",
    "print(\"  - plot_tile_samples(sample_size=50000)\")\n",
    "print(\"  - plot_tile_2d('1_1', which='train')\")\n",
    "print(\"  - plot_tile_3d_open3d('2_2', which='test')\")\n",
    "print(\"  - run_shap_for_model(clf, np.vstack([X_train_spatial, X_test_spatial])[:,3:], ['intensity','red','green','blue'])  # model on radiometric features only\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf72f9",
   "metadata": {},
   "source": [
    "## Interactive viewing of model labels (predicted and True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# MEMORY NOTE: This cell uses X_test_spatial which is already loaded\n",
    "# Create a visualization sample to avoid loading too much data\n",
    "print(\"Creating visualization sample (100k points)...\", flush=True)\n",
    "\n",
    "# Sample indices from the test set \n",
    "sample_indices = np.random.RandomState(42).choice(len(X_test_spatial), \n",
    "                                                   min(100_000, len(X_test_spatial)), \n",
    "                                                   replace=False)\n",
    "X_plot = X_test_spatial[sample_indices]\n",
    "\n",
    "# get predicted labels from the trained model\n",
    "y_pred = clf_spatial_fast.predict(X_plot)\n",
    "\n",
    "# convert numeric codes to strings\n",
    "class_map = {\n",
    "    1: \"carriageway\",\n",
    "    2: \"sidewalk\",\n",
    "    3: \"other\",\n",
    "    11: \"carriageway\",\n",
    "    \"carriageway\": \"carriageway\",\n",
    "    \"sidewalk\": \"sidewalk\",\n",
    "    \"other\": \"other\"\n",
    "}\n",
    "labels = pd.Series(y_pred).map(class_map).fillna(\"other\")\n",
    "\n",
    "# assign RGB colors per predicted class\n",
    "color_map = {\n",
    "    \"carriageway\": [0.6, 0.6, 0.6],  # grey\n",
    "    \"sidewalk\": [1.0, 0.5, 0.1],     # orange\n",
    "    \"other\": [0.3, 0.8, 0.3]         # green\n",
    "}\n",
    "colors = np.array([color_map[lbl] for lbl in labels])\n",
    "\n",
    "# create point cloud for visualization\n",
    "# Extract X, Y, Z from the feature array\n",
    "pcd_pred = o3d.geometry.PointCloud()\n",
    "pcd_pred.points = o3d.utility.Vector3dVector(X_plot[:, :3])  # First 3 columns are X, Y, Z\n",
    "pcd_pred.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# visualize\n",
    "o3d.visualization.draw_geometries([pcd_pred], window_name=\"Predicted Labels\")\n",
    "\n",
    "# CLEANUP: Free memory after visualization\n",
    "del X_plot, y_pred, colors, labels, pcd_pred, sample_indices\n",
    "gc.collect()\n",
    "print(\"‚úÖ Visualization complete and memory cleaned up\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f2d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar-sidewalks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
